library(cluster)
library(LICORS)
library(kknn)
#Defining functions of our algorithms
#----------------------------------------------------------------------------------------
f1 <- function(x){kmeans(x, centers = 30, iter.max = 20)$cluster} #kmeans
f2 <- function(x){pam(x, k=30)$clustering} #kmedoids
f3 <- function(x){kmeanspp(x, k=30, start = "random", iter.max = 10)$cluster} #kmpp
f4 <- function(x){find_k <- train.kknn(x[,ncol(x)] ~ .,
data = x,
kmax = 35,
kernel = "gaussian",
kcv = 5)
return(specClust(x, nn = find_k$best.parameters$k, method = "symmetric")$cluster)}
f5 <- function(x){find_k <- train.kknn(x[,ncol(x)] ~ .,
data = x,
kmax = 35,
kernel = "gaussian",
kcv = 5)
return(specClust(x, nn = find_k$best.parameters$k, method = "random-walk")$cluster)}
#----------------------------------------------------------------------------------------
algos <- c(f1, f2, f3, f4, f5)
standard_deviations <- function(data, algorithm){
#data is our sample data
#algorithm is either 1, 2, 3, 4, or 5, where:
#1: kmeans 2:kmedoids 3:kmpp 4:spcc-symm 5:spcc-randomwalk
SSW <- integer(1000)
SSB <- integer(1000)
Time <- integer(1000)
data$cluster = algos[[algorithm]](data)
cluster_performance(data, "cluster")
measures <- data.frame(SSW = SSW, SSB = SSB)
for(i in 1:100) {
t = proc.time()
data$cluster = algos[[algorithm]](data)
measures[i,] = cluster_performance(data, "cluster")
Time[i] = (proc.time() - t)[2]
}
return(cbind(measures, Time))
}
p1 = proc.time()
km_repeated = standard_deviations(sample, 1)
p1 = (proc.time() - p1)
sample <- reduced[sample(1:nrow(reduced) , 20)]
sample <- reduced[sample(1:nrow(reduced) , 20),]
sample
dim(sample)
reduced <- read.csv("C:/Users/Nura/Desktop/Jacobs/reduced.csv", stringsAsFactors=FALSE)
reduced <- reduced[,-1]
dim(reduced)
reduced$relative_lateness = reduced$relative_lateness + 70 #Adding a constant to the data before taking the log transform in order to remove the negative values
set.seed(100)
sample <- reduced[sample(1:nrow(reduced) , 20),]
sample
standard_deviations <- function(data, algorithm){
#data is our sample data
#algorithm is either 1, 2, 3, 4, or 5, where:
#1: kmeans 2:kmedoids 3:kmpp 4:spcc-symm 5:spcc-randomwalk
SSW <- integer(10)
SSB <- integer(10)
Time <- integer(10)
data$cluster = algos[[algorithm]](data)
cluster_performance(data, "cluster")
measures <- data.frame(SSW = SSW, SSB = SSB)
for(i in 1:10) {
t = proc.time()
data$cluster = algos[[algorithm]](data)
measures[i,] = cluster_performance(data, "cluster")
Time[i] = (proc.time() - t)[2]
}
return(cbind(measures, Time))
}
#data = f1(sample)
#Running Everything
#----------------------------------------------------------------------------------------
p1 = proc.time()
km_repeated = standard_deviations(sample, 1)
p1 = (proc.time() - p1)
sample_data <- reduced[sample(1:nrow(reduced) , 20),]
reduced <- read.csv("C:/Users/Nura/Desktop/Jacobs/reduced.csv", stringsAsFactors=FALSE)
reduced <- reduced[,-1]
#print(reduced)
reduced$relative_lateness = reduced$relative_lateness + 70 #Adding a constant to the data before taking the log transform in order to remove the negative values
set.seed(100)
sample_data <- reduced[sample(1:nrow(reduced) , 20),]
#========================================================================================
#Cluster_performance function to calculate SSW and SSB
#========================================================================================
cluster_performance<-function(dat,
cl){
means<-sapply(1:max(dat[,cl]), function(x){
unlist(apply(dat[,1:(ncol(dat)-1)], 2, function(y){
mean(y[which(dat[,cl]==x)])
}))
})
trans_dat<-t(sapply(1:nrow(dat), function(x){
unlist(apply(dat[x,1:(ncol(dat)-1)],1,function(y){
(as.vector(y)-as.vector(means[,dat[x,cl]]))^2
}))
}))
SSW<-t(sapply(1:max(dat[,cl]), function(x){
unlist(apply(trans_dat, 2, function(y){
sum(y[which(dat[,cl]==x)])
}))
}))
colnames(SSW)<-colnames(dat[,1:(ncol(dat)-1)])
rownames(SSW)<-1:max(dat[,cl])
SSW_p_c<-apply(SSW,1,sum)
SSW_p_p<-apply(SSW,2,sum)
SSB<-sapply(1:nrow(means), function(x){
sapply(1:ncol(means), function(y){
nrow(dat[which(dat[,cl]==y),])*(means[x,y]-mean(dat[,x]))^2
})
})
colnames(SSB)<-colnames(dat[,1:(ncol(dat)-1)])
rownames(SSB)<-1:max(dat[,cl])
SSB_p_c<-apply(SSB,1,sum)
SSB_p_p<-apply(SSB,2,sum)
out<-as.matrix(cbind(sum(SSW),sum(SSB)))
colnames(out)<-c("SSW","SSB")
return(out)
}
#========================================================================================
#Standard Deviation Function to calculate SD of results
#========================================================================================
library(cluster)
library(LICORS)
library(kknn)
#Defining functions of our algorithms
#----------------------------------------------------------------------------------------
f1 <- function(x){kmeans(x, centers = 30, iter.max = 20)$cluster} #kmeans
f2 <- function(x){pam(x, k=30)$clustering} #kmedoids
f3 <- function(x){kmeanspp(x, k=30, start = "random", iter.max = 10)$cluster} #kmpp
f4 <- function(x){find_k <- train.kknn(x[,ncol(x)] ~ .,
data = x,
kmax = 35,
kernel = "gaussian",
kcv = 5)
return(specClust(x, nn = find_k$best.parameters$k, method = "symmetric")$cluster)}
f5 <- function(x){find_k <- train.kknn(x[,ncol(x)] ~ .,
data = x,
kmax = 35,
kernel = "gaussian",
kcv = 5)
return(specClust(x, nn = find_k$best.parameters$k, method = "random-walk")$cluster)}
#----------------------------------------------------------------------------------------
algos <- c(f1, f2, f3, f4, f5)
standard_deviations <- function(data, algorithm){
#data is our sample data
#algorithm is either 1, 2, 3, 4, or 5, where:
#1: kmeans 2:kmedoids 3:kmpp 4:spcc-symm 5:spcc-randomwalk
SSW <- integer(10)
SSB <- integer(10)
Time <- integer(10)
data$cluster = algos[[algorithm]](data)
cluster_performance(data, "cluster")
measures <- data.frame(SSW = SSW, SSB = SSB)
for(i in 1:10) {
t = proc.time()
data$cluster = algos[[algorithm]](data)
measures[i,] = cluster_performance(data, "cluster")
Time[i] = (proc.time() - t)[2]
}
return(cbind(measures, Time))
}
#data = f1(sample_data)
#Running Everything
#----------------------------------------------------------------------------------------
p1 = proc.time()
km_repeated = standard_deviations(sample_data, 1)
p1 = (proc.time() - p1)
?sample
dim(sample_data)
reduced <- read.csv("C:/Users/Nura/Desktop/Jacobs/reduced.csv", stringsAsFactors=FALSE)
reduced <- reduced[,-1]
#print(reduced)
reduced$relative_lateness = reduced$relative_lateness + 70 #Adding a constant to the data before taking the log transform in order to remove the negative values
set.seed(100)
sample_data <- reduced[sample(1:nrow(reduced) , 100),]
#========================================================================================
#Cluster_performance function to calculate SSW and SSB
#========================================================================================
cluster_performance<-function(dat,
cl){
means<-sapply(1:max(dat[,cl]), function(x){
unlist(apply(dat[,1:(ncol(dat)-1)], 2, function(y){
mean(y[which(dat[,cl]==x)])
}))
})
trans_dat<-t(sapply(1:nrow(dat), function(x){
unlist(apply(dat[x,1:(ncol(dat)-1)],1,function(y){
(as.vector(y)-as.vector(means[,dat[x,cl]]))^2
}))
}))
SSW<-t(sapply(1:max(dat[,cl]), function(x){
unlist(apply(trans_dat, 2, function(y){
sum(y[which(dat[,cl]==x)])
}))
}))
colnames(SSW)<-colnames(dat[,1:(ncol(dat)-1)])
rownames(SSW)<-1:max(dat[,cl])
SSW_p_c<-apply(SSW,1,sum)
SSW_p_p<-apply(SSW,2,sum)
SSB<-sapply(1:nrow(means), function(x){
sapply(1:ncol(means), function(y){
nrow(dat[which(dat[,cl]==y),])*(means[x,y]-mean(dat[,x]))^2
})
})
colnames(SSB)<-colnames(dat[,1:(ncol(dat)-1)])
rownames(SSB)<-1:max(dat[,cl])
SSB_p_c<-apply(SSB,1,sum)
SSB_p_p<-apply(SSB,2,sum)
out<-as.matrix(cbind(sum(SSW),sum(SSB)))
colnames(out)<-c("SSW","SSB")
return(out)
}
#========================================================================================
#Standard Deviation Function to calculate SD of results
#========================================================================================
library(cluster)
library(LICORS)
library(kknn)
#Defining functions of our algorithms
#----------------------------------------------------------------------------------------
f1 <- function(x){kmeans(x, centers = 30, iter.max = 20)$cluster} #kmeans
f2 <- function(x){pam(x, k=30)$clustering} #kmedoids
f3 <- function(x){kmeanspp(x, k=30, start = "random", iter.max = 10)$cluster} #kmpp
f4 <- function(x){find_k <- train.kknn(x[,ncol(x)] ~ .,
data = x,
kmax = 35,
kernel = "gaussian",
kcv = 5)
return(specClust(x, nn = find_k$best.parameters$k, method = "symmetric")$cluster)}
f5 <- function(x){find_k <- train.kknn(x[,ncol(x)] ~ .,
data = x,
kmax = 35,
kernel = "gaussian",
kcv = 5)
return(specClust(x, nn = find_k$best.parameters$k, method = "random-walk")$cluster)}
#----------------------------------------------------------------------------------------
algos <- c(f1, f2, f3, f4, f5)
standard_deviations <- function(data, algorithm){
#data is our sample data
#algorithm is either 1, 2, 3, 4, or 5, where:
#1: kmeans 2:kmedoids 3:kmpp 4:spcc-symm 5:spcc-randomwalk
SSW <- integer(100)
SSB <- integer(100)
Time <- integer(100)
data$cluster = algos[[algorithm]](data)
cluster_performance(data, "cluster")
measures <- data.frame(SSW = SSW, SSB = SSB)
for(i in 1:10) {
t = proc.time()
data$cluster = algos[[algorithm]](data)
measures[i,] = cluster_performance(data, "cluster")
Time[i] = (proc.time() - t)[2]
}
return(cbind(measures, Time))
}
#data = f1(sample_data)
#Running Everything
#----------------------------------------------------------------------------------------
p1 = proc.time()
km_repeated = standard_deviations(sample_data, 1)
p1 = (proc.time() - p1)
km_repeated
standard_deviations <- function(data, algorithm){
#data is our sample data
#algorithm is either 1, 2, 3, 4, or 5, where:
#1: kmeans 2:kmedoids 3:kmpp 4:spcc-symm 5:spcc-randomwalk
SSW <- integer(100)
SSB <- integer(100)
Time <- integer(100)
data$cluster = algos[[algorithm]](data)
cluster_performance(data, "cluster")
measures <- data.frame(SSW = SSW, SSB = SSB)
for(i in 1:100) {
t = proc.time()
data$cluster = algos[[algorithm]](data)
measures[i,] = cluster_performance(data, "cluster")
Time[i] = (proc.time() - t)[2]
}
return(cbind(measures, Time))
}
#data = f1(sample_data)
#Running Everything
#----------------------------------------------------------------------------------------
p1 = proc.time()
km_repeated = standard_deviations(sample_data, 1)
p1 = (proc.time() - p1)
km_repeated
p2 = proc.time()
kmed_repeated = standard_deviations(sample_data, 2)
p2 = (proc.time() - p2)
kmed_repeated
p3 = proc.time()
kmpp_repeated = standard_deviations(sample_data, 3)
p3 = (proc.time() - p3)
reduced <- read.csv("C:/Users/Nura/Desktop/Jacobs/reduced.csv", stringsAsFactors=FALSE)
reduced <- reduced[,-1]
#print(reduced)
reduced$relative_lateness = reduced$relative_lateness + 70 #Adding a constant to the data before taking the log transform in order to remove the negative values
set.seed(100)
sample_data <- reduced[sample(1:nrow(reduced) , 100),]
#========================================================================================
#Cluster_performance function to calculate SSW and SSB
#========================================================================================
cluster_performance<-function(dat,
cl){
means<-sapply(1:max(dat[,cl]), function(x){
unlist(apply(dat[,1:(ncol(dat)-1)], 2, function(y){
mean(y[which(dat[,cl]==x)])
}))
})
trans_dat<-t(sapply(1:nrow(dat), function(x){
unlist(apply(dat[x,1:(ncol(dat)-1)],1,function(y){
(as.vector(y)-as.vector(means[,dat[x,cl]]))^2
}))
}))
SSW<-t(sapply(1:max(dat[,cl]), function(x){
unlist(apply(trans_dat, 2, function(y){
sum(y[which(dat[,cl]==x)])
}))
}))
colnames(SSW)<-colnames(dat[,1:(ncol(dat)-1)])
rownames(SSW)<-1:max(dat[,cl])
SSW_p_c<-apply(SSW,1,sum)
SSW_p_p<-apply(SSW,2,sum)
SSB<-sapply(1:nrow(means), function(x){
sapply(1:ncol(means), function(y){
nrow(dat[which(dat[,cl]==y),])*(means[x,y]-mean(dat[,x]))^2
})
})
colnames(SSB)<-colnames(dat[,1:(ncol(dat)-1)])
rownames(SSB)<-1:max(dat[,cl])
SSB_p_c<-apply(SSB,1,sum)
SSB_p_p<-apply(SSB,2,sum)
out<-as.matrix(cbind(sum(SSW),sum(SSB)))
colnames(out)<-c("SSW","SSB")
return(out)
}
#========================================================================================
#Standard Deviation Function to calculate SD of results
#========================================================================================
library(cluster)
library(LICORS)
library(kknn)
#Defining functions of our algorithms
#----------------------------------------------------------------------------------------
f1 <- function(x){kmeans(x, centers = 30, iter.max = 20)$cluster} #kmeans
f2 <- function(x){pam(x, k=30)$clustering} #kmedoids
f3 <- function(x){kmeanspp(x, k=30, start = "random", iter.max = 10)$cluster} #kmpp
f4 <- function(x){find_k <- train.kknn(x[,ncol(x)] ~ .,
data = x,
kmax = 35,
kernel = "gaussian",
kcv = 5)
return(specClust(x, nn = find_k$best.parameters$k, method = "symmetric")$cluster)}
f5 <- function(x){find_k <- train.kknn(x[,ncol(x)] ~ .,
data = x,
kmax = 35,
kernel = "gaussian",
kcv = 5)
return(specClust(x, nn = find_k$best.parameters$k, method = "random-walk")$cluster)}
#----------------------------------------------------------------------------------------
algos <- c(f1, f2, f3, f4, f5)
standard_deviations <- function(data, algorithm){
#data is our sample data
#algorithm is either 1, 2, 3, 4, or 5, where:
#1: kmeans 2:kmedoids 3:kmpp 4:spcc-symm 5:spcc-randomwalk
SSW <- integer(10)
SSB <- integer(10)
Time <- integer(10)
data$cluster = algos[[algorithm]](data)
cluster_performance(data, "cluster")
measures <- data.frame(SSW = SSW, SSB = SSB)
for(i in 1:10) {
t = proc.time()
data$cluster = algos[[algorithm]](data)
measures[i,] = cluster_performance(data, "cluster")
Time[i] = (proc.time() - t)[2]
}
return(cbind(measures, Time))
}
#data = f1(sample_data)
#Running Everything
#----------------------------------------------------------------------------------------
p1 = proc.time()
km_repeated = standard_deviations(sample_data, 1)
p1 = (proc.time() - p1)
p2 = proc.time()
kmed_repeated = standard_deviations(sample_data, 2)
p2 = (proc.time() - p2)
p3 = proc.time()
kmpp_repeated = standard_deviations(sample_data, 3)
p3 = (proc.time() - p3)
p4 = proc.time()
spc_sim = standard_deviations(sample_data, 4)
p4 = (proc.time() - p4)
p5 = proc.time()
spc_rwalk = standard_deviations(sample_data, 5)
p5 = (proc.time() - p5)
output <- data.frame("Mean SSW" = c(mean(km_repeated[,1]),
mean(kmed_repeated[,1]),
mean(kmpp_repeated[,1]),
mean(spc_sim[,1]),
mean(spc_rwalk[,1])),
"Mean SSB" = c(mean(km_repeated[,2]),
mean(kmed_repeated[,2]),
mean(kmpp_repeated[,2]),
mean(spc_sim[,2]),
mean(spc_rwalk[,2])),
"SD SSW" = c(sd(km_repeated[,1]),
sd(kmed_repeated[,1]),
sd(kmpp_repeated[,1]),
sd(spc_sim[,1]),
sd(spc_rwalk[,1])),
"SD SSB" = c(sd(km_repeated[,2]),
sd(kmed_repeated[,2]),
sd(kmpp_repeated[,2]),
sd(spc_sim[,2]),
sd(spc_rwalk[,2])),
"Mean Run Times" = c(mean(km_repeated[,3]),
mean(kmed_repeated[,3]),
mean(kmpp_repeated[,3]),
mean(spc_sim[,3]),
mean(spc_rwalk[,3])),
"SD Run Times" = c(sd(km_repeated[,3]),
sd(kmed_repeated[,3]),
sd(kmpp_repeated[,3]),
sd(spc_sim[,3]),
sd(spc_rwalk[,3])),
"Overall Time" = c(p1[3], p2[3], p3[3], p4[3], p5[3]))
write.csv(output, file = "clustering_output.csv")
output
print(head(spc_rwalk))
calculate_z_scores <- function(data,
max_number_of_centers,
outside_parameter,
size_parameter_space,
means_of_means=TRUE,
no_permutations=1000
)
{
print(paste("Beginning z-score calculation at ", Sys.time(),sep=""))
z<-matrix(-99, max_number_of_centers, max_number_of_centers-1)
for(i in 1:ncol(z)){ # cluster configuration (i.e. data set partitioned into 2, 3, 4 clusters)
for (j in 1:(i+1)){ # number of the cluster (first, second cluster etc.)
clust<-data[which(data[,i+size_parameter_space]==j),outside_parameter] #the cluster affiliations should be appended to the parameter space
if(length(clust)!=0){ #it could happen, that by removing the excluded sample, entire clusters are removed, not just single data points
cluster_col <- length(clust)
if(means_of_means){
resample_array<-sapply(1:no_permutations,
function(x) mean(as.numeric(sample(data[,outside_parameter],size=length(clust),replace=FALSE)))
)
}else{
resample_array<-sapply(1:no_permutations,
function(x) (sample(data[,outside_parameter],size=length(clust),replace=FALSE))
)
}
b_star <- mean(as.numeric(data[which(data[,i+size_parameter_space]==j),outside_parameter]), na.rm=TRUE)
b_ <- mean(as.numeric(resample_array), na.rm=TRUE)
sigma_b_star <- sd(as.numeric(resample_array), na.rm=TRUE) # sample s.d.
z[j,i] <- (b_star-b_)/sigma_b_star #z-score formula; No absolute values
if (is.infinite(z[j,i])) {
z[j,i]<-0 # if z-score infinite, set to 0
}
if (is.na(z[j,i])) {
z[j,i]<-0 # if z-score na, set to 0
}
}else{
z[j,i]<-0
}
}
}
print(paste("Z-score calculation completed at ", Sys.time(),sep=""))
return(z)
}
14*3
14*4
15*3
15*4
envpath <- "C:/Users/Nura/Desktop/Independent Research/BBC"
setwd(envpath)
folders <- c("business",
"politics",
"entertainment",
"sport",
"tech")
folder = 1
new_envpath <- paste0(envpath, "/", folders[folder])
new_envpath
folders <- c("business",
"entertainment",
"politics",
"sport",
"tech")
?file.exists
file.exists(paste0(new_envpath, "001.txt"))
file.exists(paste0(new_envpath, "001.txt"))
file.exists(paste0(new_envpath, "/001.txt"))
file.exists(paste0(new_envpath, "/001.txt")))
paste0(new_envpath, "/001.txt")
file.exists(paste0(new_envpath, "/001.txt"))
file.exists(paste0(new_envpath, "/011.txt"))
new_envpath <- paste0(envpath, "/bbc/", folders[folder])
setwd(new_envpath)
file.exists(paste0(new_envpath, "/011.txt"))
file.exists(paste0(new_envpath, "/001.txt"))
file.exists(paste0(new_envpath, "/701.txt"))
001:10
rm(folder)
